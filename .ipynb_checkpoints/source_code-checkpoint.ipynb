{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import Tokenizer, RegexTokenizer\n",
    "from pyspark.ml.classification import LinearSVC\n",
    "from pyspark.sql.functions import col, udf\n",
    "from pyspark.sql.types import IntegerType\n",
    "from pyspark.ml.feature import NGram,HashingTF, IDF\n",
    "from pyspark.ml.feature import StandardScaler\n",
    "from pyspark.sql.functions import lit\n",
    "from pyspark.mllib.feature import StandardScaler, StandardScalerModel\n",
    "from pyspark.mllib.linalg import Vectors\n",
    "from pyspark.mllib.util import MLUtils\n",
    "from pyspark.ml.classification import LogisticRegression, OneVsRest\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.sql import Row\n",
    "from pyspark.ml.feature import RegexTokenizer, StopWordsRemover, CountVectorizer\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml.feature import Word2Vec\n",
    "\n",
    "from pyspark import SparkContext\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    spark = SparkSession\\\n",
    "        .builder\\\n",
    "        .appName(\"Detecting-Malicious-URL App\")\\\n",
    "        .getOrCreate()\n",
    "\n",
    "#Reading in the URL file and storing into dataframe\n",
    "data_df = spark.read.csv(path='processed_data/dataset_customized.csv',\n",
    "                        sep=',',\n",
    "                        encoding='UTF-8',\n",
    "                        comment=None,\n",
    "                        header=True, \n",
    "                        inferSchema=True)\n",
    "\n",
    "#Uncomment the following two lines if kaggle datasets is used...and replace data_df variable above with raw_data\n",
    "#indexer = StringIndexer(inputCol=\"lable\", outputCol=\"label\")\n",
    "#data_df = indexer.fit(raw_data).transform(raw_data).select(\"url\", \"label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Dataset Count: 957566\n",
      "Test Dataset Count: 240580\n",
      "Total Dataset Count: 1198146\n"
     ]
    }
   ],
   "source": [
    "#Tokennize the TrainData - sparse the URL string into words\n",
    "regexTokenizer = RegexTokenizer(inputCol=\"url\", outputCol=\"Words\", pattern=\"\\\\W\")\n",
    "\n",
    "#determing components to be removed in the URL\n",
    "add_stopWords = [\"http\", \"https\", \"www\", \"ftp\"]\n",
    "\n",
    "#Removing the above stop words  from the tokenized data\n",
    "stopwordsRemover = StopWordsRemover(inputCol=regexTokenizer.getOutputCol(), outputCol=\"Filtered\").setStopWords(add_stopWords)\n",
    "\n",
    "#Convert the words to ngrams. Note: this is not used in production as it gives less results during model training\n",
    "ngram = NGram(n=3, inputCol=stopwordsRemover.getOutputCol(), outputCol=\"Ngrams\")\n",
    "\n",
    "#Word2Vec - Note: this is not used in production as it gives less results during model training\n",
    "word2Vec = Word2Vec(vectorSize=1000, minCount=5, inputCol=stopwordsRemover.getOutputCol(), outputCol=\"features\")\n",
    "\n",
    "#Hashing the data - Note: this is not used in production as it gives less results during model training\n",
    "hashingTF = HashingTF(inputCol=ngram.getOutputCol(), outputCol=\"rawFeatures\")\n",
    "\n",
    "#Note: this is not used in production as it gives less results during model training\n",
    "idf = IDF(inputCol=hashingTF.getOutputCol(), outputCol=\"features\") \n",
    "\n",
    "#CountVectorizer converts the the words into feature vectors - Thi is used as it gives better results\n",
    "countVectors = CountVectorizer(inputCol=stopwordsRemover.getOutputCol(), outputCol=\"features\", vocabSize=10000, minDF=5)\n",
    "\n",
    "#creating the pipepline of steps to be performed in order\n",
    "pipeline = Pipeline(stages=[regexTokenizer,stopwordsRemover, countVectors ])\n",
    "\n",
    "# Fit the pipeline to training documents.\n",
    "pipelineFit = pipeline.fit(data_df)\n",
    "\n",
    "#Transform the pipeline to dataset\n",
    "dataset = pipelineFit.transform(data_df)\n",
    "\n",
    "#randomly split the dataset to traning and testing 80%, 20% respectively\n",
    "(trainingData, testData) = dataset.randomSplit([0.8, 0.2], seed = 100)\n",
    "print(\"Training Dataset Count: \" + str(trainingData.count()))\n",
    "print(\"Test Dataset Count: \" + str(testData.count()))\n",
    "print(\"Total Dataset Count: \" + str(dataset.count()))\n",
    "#dataset.show(truncate = 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Root Mean Squared Error (RMSE) on test data = 0.342964\n",
      "\n",
      "Accuracy on Test Data = 88.6028\n",
      "\n",
      "Root Mean Squared Error (RMSE) on test data = 0.342903\n",
      "\n",
      "Accuracy on Test Data = 88.5872\n",
      "\n",
      "Root Mean Squared Error (RMSE) on test data = 0.342958\n",
      "\n",
      "Accuracy on Test Data = 88.5863\n",
      "\n",
      "Root Mean Squared Error (RMSE) on test data = 0.34297\n",
      "\n",
      "Accuracy on Test Data = 88.601\n",
      "\n",
      "Root Mean Squared Error (RMSE) on test data = 0.34297\n",
      "\n",
      "Accuracy on Test Data = 88.601\n",
      "\n",
      "Root Mean Squared Error (RMSE) on test data = 0.342909\n",
      "\n",
      "Accuracy on Test Data = 88.5856\n",
      "\n",
      "Root Mean Squared Error (RMSE) on test data = 0.342964\n",
      "\n",
      "Accuracy on Test Data = 88.5993\n",
      "\n",
      "Root Mean Squared Error (RMSE) on test data = 0.342933\n",
      "\n",
      "Accuracy on Test Data = 88.6035\n",
      "\n",
      "Root Mean Squared Error (RMSE) on test data = 0.342903\n",
      "\n",
      "Accuracy on Test Data = 88.59\n",
      "\n",
      "Root Mean Squared Error (RMSE) on test data = 0.342952\n",
      "\n",
      "Accuracy on Test Data = 88.6015\n",
      "\n",
      "Root Mean Squared Error (RMSE) on test data = 0.342927\n",
      "\n",
      "Accuracy on Test Data = 88.6027\n",
      "\n",
      "Root Mean Squared Error (RMSE) on test data = 0.342933\n",
      "\n",
      "Accuracy on Test Data = 88.5996\n",
      "\n",
      "Root Mean Squared Error (RMSE) on test data = 0.342952\n",
      "\n",
      "Accuracy on Test Data = 88.5877\n",
      "\n",
      "Root Mean Squared Error (RMSE) on test data = 0.342958\n",
      "\n",
      "Accuracy on Test Data = 88.5863\n",
      "\n",
      "Root Mean Squared Error (RMSE) on test data = 0.342909\n",
      "\n",
      "Accuracy on Test Data = 88.5912\n",
      "\n",
      "Root Mean Squared Error (RMSE) on test data = 0.342909\n",
      "\n",
      "Accuracy on Test Data = 88.601\n",
      "\n",
      "Root Mean Squared Error (RMSE) on test data = 0.342976\n",
      "\n",
      "Accuracy on Test Data = 88.5832\n",
      "\n",
      "Root Mean Squared Error (RMSE) on test data = 0.342964\n",
      "\n",
      "Accuracy on Test Data = 88.5897\n",
      "\n",
      "Root Mean Squared Error (RMSE) on test data = 0.342994\n",
      "\n",
      "Accuracy on Test Data = 88.5895\n",
      "\n",
      "Root Mean Squared Error (RMSE) on test data = 0.342903\n",
      "\n",
      "Accuracy on Test Data = 88.5969\n",
      "\n",
      "Root Mean Squared Error (RMSE) on test data = 0.342927\n",
      "\n",
      "Accuracy on Test Data = 88.5933\n",
      "\n",
      "Root Mean Squared Error (RMSE) on test data = 0.343006\n",
      "\n",
      "Accuracy on Test Data = 88.5952\n",
      "\n",
      "Root Mean Squared Error (RMSE) on test data = 0.342903\n",
      "\n",
      "Accuracy on Test Data = 88.5952\n",
      "\n",
      "Root Mean Squared Error (RMSE) on test data = 0.34297\n",
      "\n",
      "Accuracy on Test Data = 88.5906\n",
      "\n",
      "Root Mean Squared Error (RMSE) on test data = 0.342921\n",
      "\n",
      "Accuracy on Test Data = 88.595\n",
      "\n",
      "Root Mean Squared Error (RMSE) on test data = 0.342939\n",
      "\n",
      "Accuracy on Test Data = 88.5998\n",
      "\n",
      "Root Mean Squared Error (RMSE) on test data = 0.342897\n",
      "\n",
      "Accuracy on Test Data = 88.5994\n",
      "\n",
      "Root Mean Squared Error (RMSE) on test data = 0.342879\n",
      "\n",
      "Accuracy on Test Data = 88.5888\n",
      "\n",
      "Root Mean Squared Error (RMSE) on test data = 0.34297\n",
      "\n",
      "Accuracy on Test Data = 88.5972\n",
      "\n",
      "Root Mean Squared Error (RMSE) on test data = 0.342988\n",
      "\n",
      "Accuracy on Test Data = 88.6045\n",
      "\n",
      "Average Accuracy on test for 30 run is: 88.5948\n"
     ]
    }
   ],
   "source": [
    "#==============[ LOGISTIC REGRESSION ]=========================\n",
    "accuracy = 0.0\n",
    "average_accuracy = 0.0\n",
    "\n",
    "\n",
    "# Build logistic regresssion model\n",
    "for i in range(1,31):\n",
    "    # Fit the pipeline to training documents.\n",
    "    pipelineFit = pipeline.fit(data_df)\n",
    "\n",
    "    #Transform the pipeline to dataset\n",
    "    dataset = pipelineFit.transform(data_df)\n",
    "    \n",
    "    #randomly split the dataset to traning and testing 80%, 20% respectively\n",
    "    (trainingData, testData) = dataset.randomSplit([0.8, 0.2], seed = 100)\n",
    "    \n",
    "    lr = LogisticRegression(maxIter=10000, regParam=0.3, elasticNetParam=0, family = \"binomial\")\n",
    "    # Train model using logisitic regression\n",
    "    lrModel = lr.fit(trainingData)\n",
    "\n",
    "#beta = np.sort(lrModel.coefficients)\n",
    "#plt.plot(beta)\n",
    "#plt.ylabel('Beta Coefficients')\n",
    "#plt.show()\n",
    "\n",
    "# Extract the summary from the returned LogisticRegressionModel instance trained\n",
    "#trainingSummary = lrModel.summary\n",
    "\n",
    "#Obtain the objective per iteration\n",
    "#objectiveHistory = trainingSummary.objectiveHistory\n",
    "#plt.plot(objectiveHistory)\n",
    "#plt.ylabel('Objective Function')\n",
    "#plt.xlabel('Iteration')\n",
    "#plt.show()\n",
    "\n",
    "#pr = trainingSummary.pr.toPandas()\n",
    "#plt.plot(pr['recall'],pr['precision'])\n",
    "#plt.ylabel('Precision')\n",
    "#plt.xlabel('Recall')\n",
    "#plt.show()\n",
    "\n",
    "#Obtain the receiver-operating characteristic as a dataframe and areaUnderROC.\n",
    "#print(\"areaUnderROC: \" + str(trainingSummary.areaUnderROC))\n",
    "\n",
    "#trainingSummary.roc.show(n=10, truncate=15)\n",
    "#roc = trainingSummary.roc.toPandas()\n",
    "#plt.plot(roc['FPR'],roc['TPR'])\n",
    "#plt.ylabel('False Positive Rate')\n",
    "#plt.xlabel('True Positive Rate')\n",
    "#plt.title('ROC Curve')\n",
    "#plt.show()\n",
    "\n",
    "#Set the model threshold to maximize F-Measure\n",
    "#trainingSummary.fMeasureByThreshold.show(n=10, truncate = 15)\n",
    "#f = trainingSummary.fMeasureByThreshold.toPandas()\n",
    "#plt.plot(f['threshold'],f['F-Measure'])\n",
    "#plt.ylabel('F-Measure')\n",
    "#plt.xlabel('Threshold')\n",
    "#plt.show()\n",
    "\n",
    "#Doing the prediction using test data\n",
    "#Label is not used in test data\n",
    "    predictions = lrModel.transform(testData)\n",
    "\n",
    "  #  predictions.select(\"url\", \"label\", \"prediction\").show(n=5, truncate = 100)\n",
    "# Select (prediction, true label) and compute test error\n",
    "    evaluator = RegressionEvaluator(\n",
    "        labelCol=\"label\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "    rmse = evaluator.evaluate(predictions)\n",
    "    print(\"\\nRoot Mean Squared Error (RMSE) on test data = %g\" % rmse)\n",
    "\n",
    "    # Evaluate model\n",
    "    evaluator = BinaryClassificationEvaluator()\n",
    "    accuracy = evaluator.evaluate(predictions)\n",
    "    \n",
    "    average_accuracy = accuracy + average_accuracy\n",
    "\n",
    "    print(\"\\nAccuracy on Test Data = %g\" % (accuracy*100))\n",
    "\n",
    "average_accuracy = average_accuracy/i    \n",
    "print(\"\\nAverage Accuracy on test for %i run is: %g\" % (i, (average_accuracy *100)))\n",
    "#evaluator = BinaryClassificationEvaluator(rawPredictionCol=\"rawPrediction\")\n",
    "#print(\"Test: Area Under ROC: \" + str(evaluator.evaluate(predictions, {evaluator.metricName: \"areaUnderROC\"})))\n",
    "\n",
    "#predictions.filter(predictions['prediction'] == 0) \\\n",
    "#    .select(\"url\", \"label\",\"prediction\") \\\n",
    "#    .orderBy(\"probability\", ascending=False) \\\n",
    "#    .show(n = 10, truncate = 80)\n",
    "#Precision measures the percentage of URLs flagged as malicious that were correctly classified\n",
    "#Recall measures the percentage of actual Malicious URLs that were correctly classified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: Area Under ROC: 0.9763079945884876\n"
     ]
    }
   ],
   "source": [
    "#==============[ Cross Validation for Logistic Regression ]=====================\n",
    "# Creating ParamGrid for Cross Validation\n",
    "paramGrid = (ParamGridBuilder()\n",
    "             .addGrid(lr.regParam, [0.1, 0.3, 0.5]) # regularization parameter\n",
    "             .addGrid(lr.elasticNetParam, [0.0, 0.1, 0.2]) # Elastic Net Parameter (Ridge = 0)\n",
    "#            .addGrid(model.maxIter, [10, 20, 50]) #Number of iterations\n",
    "#            .addGrid(idf.numFeatures, [10, 100, 1000]) # Number of features\n",
    "             .build())\n",
    "\n",
    "# Create 10-fold CrossValidator\n",
    "cv = CrossValidator(estimator=lr, \\\n",
    "                    estimatorParamMaps=paramGrid, \\\n",
    "                    evaluator=evaluator, \\\n",
    "                    numFolds=10)\n",
    "\n",
    "# Run cross validations\n",
    "cvModel = cv.fit(trainingData)\n",
    "# this will likely take a fair amount of time because of the amount of models that we're creating and testing\n",
    "\n",
    "# Use test set here so we can measure the accuracy of our model on new data\n",
    "predictions = cvModel.transform(testData)\n",
    "\n",
    "# cvModel uses the best model found from the Cross Validation\n",
    "# Evaluate best model\n",
    "print(\"Test: Area Under ROC: \" + str(evaluator.evaluate(predictions, {evaluator.metricName: \"areaUnderROC\"})))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error (RMSE) on test data = 0.266667\n",
      "\n",
      "Accuracy on Test Data = 86.9483\n",
      "Root Mean Squared Error (RMSE) on test data = 0.266714\n",
      "\n",
      "Accuracy on Test Data = 86.4946\n"
     ]
    }
   ],
   "source": [
    "#==============[ Linear Support Vector Machine ]=====================\n",
    "\n",
    "for i in range(1, 3):\n",
    "    \n",
    "     # Fit the pipeline to training documents.\n",
    "    pipelineFit = pipeline.fit(data_df)\n",
    "\n",
    "    #Transform the pipeline to dataset\n",
    "    dataset = pipelineFit.transform(data_df)\n",
    "    \n",
    "    #randomly split the dataset to traning and testing 80%, 20% respectively\n",
    "    (trainingData, testData) = dataset.randomSplit([0.8, 0.2], seed = 100)\n",
    "\n",
    "    lsvc = LinearSVC(maxIter=10, regParam=0.3)\n",
    "\n",
    "    # Fit the model\n",
    "    lsvcModel = lsvc.fit(trainingData)\n",
    "\n",
    "    predictions = lsvcModel.transform(testData)\n",
    "\n",
    "    #predictions.select(\"url\", \"label\", \"prediction\").show(n=5, truncate = 100)\n",
    "\n",
    "    # Select (prediction, true label) and compute test error\n",
    "    evaluator = RegressionEvaluator(\n",
    "        labelCol=\"label\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "    rmse = evaluator.evaluate(predictions)\n",
    "    print(\"Root Mean Squared Error (RMSE) on test data = %g\" % rmse)\n",
    "\n",
    "    # Evaluate model\n",
    "    evaluator = BinaryClassificationEvaluator()\n",
    "    accuracy = evaluator.evaluate(predictions)\n",
    "\n",
    "    print(\"\\nAccuracy on Test Data = %g\" % (accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error = 0.0689667\n",
      "\n",
      "Accuracy on Test Data = 93.1033\n",
      "Test Error = 0.0689293\n",
      "\n",
      "Accuracy on Test Data = 93.1071\n",
      "Test Error = 0.0689043\n",
      "\n",
      "Accuracy on Test Data = 93.1096\n"
     ]
    }
   ],
   "source": [
    "#==============[ One-vs-Rest classifier (a.k.a. One-vs-All ]=====================\n",
    "\n",
    "for i in range(1, 4):\n",
    "    \n",
    "     # Fit the pipeline to training documents.\n",
    "    pipelineFit = pipeline.fit(data_df)\n",
    "\n",
    "    #Transform the pipeline to dataset\n",
    "    dataset = pipelineFit.transform(data_df)\n",
    "    \n",
    "    #randomly split the dataset to traning and testing 80%, 20% respectively\n",
    "    (trainingData, testData) = dataset.randomSplit([0.8, 0.2], seed = 100)\n",
    "\n",
    "    # instantiate the base classifier.\n",
    "    lr = LogisticRegression(maxIter=10, tol=1E-6, fitIntercept=True)\n",
    "\n",
    "    # instantiate the One Vs Rest Classifier.\n",
    "    ovr = OneVsRest(classifier=lr)\n",
    "\n",
    "    # train the multiclass model.\n",
    "    ovrModel = ovr.fit(trainingData)\n",
    "\n",
    "    # score the model on test data.\n",
    "    predictions = ovrModel.transform(testData)\n",
    "\n",
    "    # obtain evaluator.\n",
    "    evaluator = MulticlassClassificationEvaluator(metricName=\"accuracy\")\n",
    "\n",
    "    evaluator1 = BinaryClassificationEvaluator()\n",
    " \n",
    "  #  predictions.select(\"url\", \"label\", \"prediction\").show(n=5, truncate = 100)\n",
    "\n",
    "\n",
    "    # compute the classification error on test data.\n",
    "    accuracy = evaluator.evaluate(predictions)\n",
    "    print(\"Test Error = %g\" % (1.0 - accuracy))\n",
    "    print(\"\\nAccuracy on Test Data = %g\" % (accuracy*100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Exception while sending command.\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/spark-2.3.0-bin-hadoop2.7/python/lib/py4j-0.10.6-src.zip/py4j/java_gateway.py\", line 1062, in send_command\n",
      "    raise Py4JNetworkError(\"Answer from Java side is empty\")\n",
      "py4j.protocol.Py4JNetworkError: Answer from Java side is empty\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/spark-2.3.0-bin-hadoop2.7/python/lib/py4j-0.10.6-src.zip/py4j/java_gateway.py\", line 908, in send_command\n",
      "    response = connection.send_command(command)\n",
      "  File \"/usr/local/spark-2.3.0-bin-hadoop2.7/python/lib/py4j-0.10.6-src.zip/py4j/java_gateway.py\", line 1067, in send_command\n",
      "    \"Error while receiving\", e, proto.ERROR_ON_RECEIVE)\n",
      "py4j.protocol.Py4JNetworkError: Error while receiving\n"
     ]
    },
    {
     "ename": "Py4JError",
     "evalue": "An error occurred while calling o10051.showString",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-5526faaf2b6f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/spark-2.3.0-bin-hadoop2.7/python/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36mshow\u001b[0;34m(self, n, truncate, vertical)\u001b[0m\n\u001b[1;32m    348\u001b[0m         \"\"\"\n\u001b[1;32m    349\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtruncate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtruncate\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 350\u001b[0;31m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshowString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvertical\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    351\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshowString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtruncate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvertical\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark-2.3.0-bin-hadoop2.7/python/lib/py4j-0.10.6-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1158\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1159\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1160\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1162\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark-2.3.0-bin-hadoop2.7/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdeco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjava_exception\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark-2.3.0-bin-hadoop2.7/python/lib/py4j-0.10.6-src.zip/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    326\u001b[0m             raise Py4JError(\n\u001b[1;32m    327\u001b[0m                 \u001b[0;34m\"An error occurred while calling {0}{1}{2}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m                 format(target_id, \".\", name))\n\u001b[0m\u001b[1;32m    329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[0mtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0manswer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mPy4JError\u001b[0m: An error occurred while calling o10051.showString"
     ]
    }
   ],
   "source": [
    "data_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
