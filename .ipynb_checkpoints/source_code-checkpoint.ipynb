{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing libraries and reading in file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>56937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label    count\n",
       "0      1    56937\n",
       "1      0  1000000"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.ml.feature import Tokenizer, RegexTokenizer\n",
    "from pyspark.ml.classification import LinearSVC\n",
    "from pyspark.sql.functions import col, udf\n",
    "from pyspark.sql.types import IntegerType\n",
    "from pyspark.ml.feature import NGram,HashingTF, IDF\n",
    "from pyspark.ml.feature import StandardScaler\n",
    "from pyspark.sql.functions import lit\n",
    "from pyspark.mllib.feature import StandardScaler, StandardScalerModel\n",
    "from pyspark.mllib.linalg import Vectors\n",
    "from pyspark.mllib.util import MLUtils\n",
    "from pyspark.ml.classification import LogisticRegression, OneVsRest\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.sql import Row\n",
    "from pyspark.ml.feature import RegexTokenizer, StopWordsRemover, CountVectorizer\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml.feature import Word2Vec\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from pyspark.mllib.evaluation import MulticlassMetrics\n",
    "from pyspark.ml.classification import NaiveBayes\n",
    "from pyspark import SparkContext\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    spark = SparkSession\\\n",
    "        .builder\\\n",
    "        .appName(\"Detecting-Malicious-URL App\")\\\n",
    "        .getOrCreate()\n",
    "\n",
    "#Reading in the URL file and storing into dataframe\n",
    "data_df = spark.read.csv(path='dataset.csv',\n",
    "                        sep=',',\n",
    "                        encoding='UTF-8',\n",
    "                        comment=None,\n",
    "                        header=True, \n",
    "                        inferSchema=True)\n",
    "\n",
    "data_df.groupby('label').count().toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Under Sample Unbalanced Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>56937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>53650</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  count\n",
       "0      1  56937\n",
       "1      0  53650"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "malicious = data_df.filter(\"label = 1\")\n",
    "bening = data_df.filter(\"label = 0\")\n",
    "\n",
    "#malicious.count()\n",
    "#bening.count()\n",
    "\n",
    "sampleRatio = malicious.count() / data_df.count()\n",
    "#print(\"sampleRatio: %g\" %sampleRatio)\n",
    "sample_bening = bening.sample(False, sampleRatio)\n",
    "\n",
    "sampled = malicious.unionAll(sample_bening)\n",
    "\n",
    "sampled.groupby('label').count().toPandas()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Ingestion and Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Dataset Count: 844745\n",
      "Test Dataset Count: 212192\n",
      "Total Dataset Count: 1056937\n",
      "+--------------------+-----+--------------------+--------------------+--------------------+\n",
      "|                 url|label|               Words|         rawfeatures|            features|\n",
      "+--------------------+-----+--------------------+--------------------+--------------------+\n",
      "|http://br-ofertas...|    1|[http, br, oferta...|(10000,[0,3,13,16...|(10000,[0,3,13,16...|\n",
      "|https://semana-da...|    1|[https, semana, d...|(10000,[0,16,24,4...|(10000,[0,16,24,4...|\n",
      "|https://scrid-app...|    1|[https, scrid, ap...|(10000,[0,24,904]...|(10000,[0,24,904]...|\n",
      "|http://my-softban...|    1|[http, my, softba...|(10000,[0,3,70,90...|(10000,[0,3,70,90...|\n",
      "|http://www.my-sof...|    1|[http, www, my, s...|(10000,[0,3,18,70...|(10000,[0,3,18,70...|\n",
      "+--------------------+-----+--------------------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Tokennize the TrainData - sparse the URL string into words\n",
    "regexTokenizer = RegexTokenizer(inputCol=\"url\", outputCol=\"Words\", pattern=\"\\\\W\")\n",
    "\n",
    "#CountVectorizer converts the the words into feature vectors - Thi is used as it gives better results\n",
    "countVectors = CountVectorizer(inputCol=regexTokenizer.getOutputCol(), outputCol=\"rawfeatures\", vocabSize=10000, minDF=5)\n",
    "\n",
    "#Note: this is not used in production as it gives less results during model training\n",
    "idf = IDF(inputCol=countVectors.getOutputCol(), outputCol=\"features\") \n",
    "\n",
    "#create the pipline \n",
    "pipeline = Pipeline(stages=[regexTokenizer, countVectors, idf ])\n",
    "\n",
    "\n",
    "# Fit the pipeline to training documents.\n",
    "pipelineFit = pipeline.fit(data_df)\n",
    "\n",
    "#Transform the pipeline to dataset\n",
    "dataset = pipelineFit.transform(data_df)\n",
    "\n",
    "#randomly split the dataset to traning and testing 80%, 20% respectively\n",
    "(trainingData, testData) = dataset.randomSplit([0.8, 0.2], seed = 100)\n",
    "print(\"\\nTraining Dataset Count: \" + str(trainingData.count()))\n",
    "print(\"Test Dataset Count: \" + str(testData.count()))\n",
    "print(\"Total Dataset Count: \" + str(dataset.count()))\n",
    "\n",
    "dataset.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>45430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>799315</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label   count\n",
       "0      1   45430\n",
       "1      0  799315"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainingData.groupby('label').count().toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Root Mean Squared Error (RMSE) on test data = 0.143229\n",
      "\n",
      "AreaUnderROC on Test Data = 99.4669\n",
      "True Positives: 7154\n",
      "True Negative: 200685\n",
      "False Positive: 0\n",
      "False Negative: 4353\n",
      "Total: 212192\n",
      "Recal: 62.1709\n",
      "Precision: 100\n",
      "Accuracy: 97.9486\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fd9c14008d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#==============[ LOGISTIC REGRESSION ]=========================\n",
    "accuracy = 0.0\n",
    "average_accuracy = 0.0\n",
    "\n",
    "\n",
    "# Build logistic regresssion model\n",
    "for i in range(1,2):\n",
    "    \n",
    "    lr = LogisticRegression(maxIter=10000, regParam=0.3, elasticNetParam=0, family = \"binomial\")\n",
    "    # Train model using logisitic regression\n",
    "    lrModel = lr.fit(trainingData)\n",
    "\n",
    "    #Doing the prediction using test data\n",
    "    #Label is not used in test data\n",
    "    predictions = lrModel.transform(testData)\n",
    "\n",
    "  #  predictions.select(\"url\", \"label\", \"prediction\").show(n=5, truncate = 100)\n",
    "# Select (prediction, true label) and compute test error\n",
    "    evaluator = RegressionEvaluator(\n",
    "        labelCol=\"label\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "    rmse = evaluator.evaluate(predictions)\n",
    "    print(\"\\nRoot Mean Squared Error (RMSE) on test data = %g\" % rmse)\n",
    "\n",
    "    # Evaluate model\n",
    "    evaluator = BinaryClassificationEvaluator()\n",
    "    accuracy = evaluator.evaluate(predictions)\n",
    "    \n",
    "    average_accuracy = accuracy + average_accuracy\n",
    "\n",
    "    print(\"\\nAreaUnderROC on Test Data = %g\" % (accuracy*100))\n",
    "    \n",
    "   # print(\"test accuracy with pipeline \" + accuracyScore(lrModel.transform(testData), \"label\", \"prediction\"))\n",
    "    #print(\"test recall for 1.0 is \" + recall(lrModel.transform(testData), \"label\", \"prediction\", 1))\n",
    "\n",
    "#average_accuracy = average_accuracy/i    \n",
    "#print(\"\\nAverage Accuracy on test for %i run is: %g\" % (i, (average_accuracy *100)))\n",
    "#evaluator = BinaryClassificationEvaluator(rawPredictionCol=\"rawPrediction\")\n",
    "#print(\"Test: Area Under ROC: \" + str(evaluator.evaluate(predictions, {evaluator.metricName: \"areaUnderROC\"})))\n",
    "#print(\"Test: Area Under PR - precision-recall curve: \" + str(evaluator.evaluate(predictions, {evaluator.metricName: \"areaUnderPR\"})))\n",
    "\n",
    "#evaluator_p = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\")\n",
    "#precision = evaluator_p.evaluate(predictions,{evaluator.metricName: \"precision\"})\n",
    "#print(\"Precision %g\" % (precision *100))\n",
    "\n",
    "#evaluator_r = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\")\n",
    "#recall_ = evaluator_p.evaluate(predictions,{evaluator.metricName: \"recall\"})\n",
    "#print(\"Recall %g\" % (recall_*100))\n",
    "\n",
    "#===========================\n",
    "df = predictions.select('prediction', 'label')\n",
    "#predictionAndLabels=df.rdd\n",
    "\n",
    "#metrics = MulticlassMetrics(predictionAndLabels) \n",
    "\n",
    "#accuracy=(cm[0][0]+cm[1][1])/cm.sum()\n",
    "#print(accuracy)\n",
    "\n",
    "tp = df[(df.label == 1) & (df.prediction == 1)].count()\n",
    "tn = df[(df.label == 0) & (df.prediction == 0)].count()\n",
    "fp = df[(df.label == 0) & (df.prediction == 1)].count()\n",
    "fn = df[(df.label == 1) & (df.prediction == 0)].count()\n",
    "\n",
    "print(\"True Positives: %g\" % tp)\n",
    "print(\"True Negative: %g\" % tn)\n",
    "print(\"False Positive: %g\" % fp)\n",
    "print(\"False Negative: %g\" % fn)\n",
    "\n",
    "print(\"Total: %g\" % (df.count()))\n",
    "\n",
    "r = float(tp)/(tp + fn)\n",
    "p = float(tp) / (tp + fp)\n",
    "a = float(tp + tn) / (tp + fp + tn + fn)\n",
    "\n",
    "print(\"Recal: %g\" %(r*100))\n",
    "print(\"Precision: %g\" %(p*100))\n",
    "print(\"Accuracy: %g\" %(a*100))\n",
    "\n",
    "#df.show(30)\n",
    "\n",
    "#===========================ploting\n",
    "\n",
    "#plt.clf()\n",
    "lr_predictions = lrModel.transform(testData)\n",
    "\n",
    "y_actu = lr_predictions.select(\"label\").toPandas()\n",
    "y_pred = lr_predictions.select(\"prediction\").toPandas()\n",
    "\n",
    "cm = confusion_matrix(y_actu, y_pred)\n",
    "\n",
    "plt.clf()\n",
    "plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Wistia)\n",
    "classNames = ['Negative','Positive']\n",
    "plt.title('LOGISTIC REGRESSION')\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "tick_marks = np.arange(len(classNames))\n",
    "plt.xticks(tick_marks, classNames, rotation=45)\n",
    "plt.yticks(tick_marks, classNames)\n",
    "\n",
    "#TN, FP, FN, TP = confusion_matrix([0, 1, 0, 1], [1, 1, 1, 0]).ravel()\n",
    "\n",
    "s = [['TN','FP'], ['FN', 'TP']]\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        plt.text(j,i, str(s[i][j])+\" = \"+str(cm[i][j]))\n",
    "plt.show()\n",
    "\n",
    "#===============================================================\n",
    "\n",
    "beta = np.sort(lrModel.coefficients)\n",
    "plt.plot(beta)\n",
    "plt.ylabel('Beta Coefficients')\n",
    "plt.show()\n",
    "\n",
    "# Extract the summary from the returned LogisticRegressionModel instance trained\n",
    "trainingSummary = lrModel.summary\n",
    "\n",
    "#Obtain the objective per iteration\n",
    "objectiveHistory = trainingSummary.objectiveHistory\n",
    "plt.plot(objectiveHistory)\n",
    "plt.ylabel('Objective Function')\n",
    "plt.xlabel('Iteration')\n",
    "plt.show()\n",
    "\n",
    "pr = trainingSummary.pr.toPandas()\n",
    "plt.plot(pr['recall'],pr['precision'])\n",
    "plt.ylabel('Precision')\n",
    "plt.xlabel('Recall')\n",
    "plt.show()\n",
    "\n",
    "#Obtain the receiver-operating characteristic as a dataframe and areaUnderROC.\n",
    "print(\"areaUnderROC: \" + str(trainingSummary.areaUnderROC))\n",
    "\n",
    "#trainingSummary.roc.show(n=10, truncate=15)\n",
    "roc = trainingSummary.roc.toPandas()\n",
    "plt.plot(roc['FPR'],roc['TPR'])\n",
    "plt.ylabel('False Positive Rate')\n",
    "plt.xlabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.show()\n",
    "\n",
    "#Set the model threshold to maximize F-Measure\n",
    "trainingSummary.fMeasureByThreshold.show(n=10, truncate = 15)\n",
    "f = trainingSummary.fMeasureByThreshold.toPandas()\n",
    "plt.plot(f['threshold'],f['F-Measure'])\n",
    "plt.ylabel('F-Measure')\n",
    "plt.xlabel('Threshold')\n",
    "plt.show()\n",
    "\n",
    "predictions.filter(predictions['prediction'] == 0) \\\n",
    "    .select(\"url\", \"label\",\"prediction\") \\\n",
    "    .orderBy(\"probability\", ascending=False) \\\n",
    "    .show(n = 10, truncate = 80)\n",
    "    \n",
    "#Precision measures the percentage of URLs flagged as malicious that were correctly classified\n",
    "#Recall measures the percentage of actual Malicious URLs that were correctly classified"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross Validation for Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#==============[ Cross Validation for Logistic Regression ]=====================\n",
    "# Creating ParamGrid for Cross Validation\n",
    "paramGrid = (ParamGridBuilder()\n",
    "             .addGrid(lr.regParam, [0.1, 0.3, 0.5]) # regularization parameter\n",
    "             .addGrid(lr.elasticNetParam, [0.0, 0.1, 0.2]) # Elastic Net Parameter (Ridge = 0)\n",
    "#            .addGrid(model.maxIter, [10, 20, 50]) #Number of iterations\n",
    "#            .addGrid(idf.numFeatures, [10, 100, 1000]) # Number of features\n",
    "             .build())\n",
    "\n",
    "# Create 10-fold CrossValidator\n",
    "cv = CrossValidator(estimator=lr, \\\n",
    "                    estimatorParamMaps=paramGrid, \\\n",
    "                    evaluator=evaluator, \\\n",
    "                    numFolds=5)\n",
    "\n",
    "# Run cross validations\n",
    "cvModel = cv.fit(trainingData)\n",
    "# this will likely take a fair amount of time because of the amount of models that we're creating and testing\n",
    "\n",
    "# Use test set here so we can measure the accuracy of our model on new data\n",
    "predictions = cvModel.transform(testData)\n",
    "\n",
    "# cvModel uses the best model found from the Cross Validation\n",
    "# Evaluate best model\n",
    "print(\"Test: Area Under ROC: \" + str(evaluator.evaluate(predictions, {evaluator.metricName: \"areaUnderROC\"})))\n",
    "\n",
    "evaluator_p = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\")\n",
    "precision = evaluator_p.evaluate(predictions,{evaluator.metricName: \"precision\"})\n",
    "print(\"Precision %g\" % (precision *100))\n",
    "\n",
    "evaluator_r = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\")\n",
    "recall = evaluator_r.evaluate(predictions,{evaluator.metricName: \"recall\"})\n",
    "print(\"Recall %g\" % (recall*100))\n",
    "\n",
    "#================================================================\n",
    "df = predictions.select('prediction', 'label')\n",
    "\n",
    "predictionAndLabels=df.rdd\n",
    "metrics = MulticlassMetrics(predictionAndLabels) \n",
    "\n",
    "\n",
    "\n",
    "tp = df[(df.label == 1) & (df.prediction == 1)].count()\n",
    "tn = df[(df.label == 0) & (df.prediction == 0)].count()\n",
    "fp = df[(df.label == 0) & (df.prediction == 1)].count()\n",
    "fn = df[(df.label == 1) & (df.prediction == 0)].count()\n",
    "\n",
    "print(\"True Positives: %g\" % tp)\n",
    "print(\"True Negative: %g\" % tn)\n",
    "print(\"False Positive: %g\" % fp)\n",
    "print(\"False Negative: %g\" % fn)\n",
    "\n",
    "print(\"Total: %g\" % (df.count()))\n",
    "\n",
    "r = float(tp)/(tp + fn)\n",
    "p = float(tp) / (tp + fp)\n",
    "a = float(tp + tn) / (tp + fp + tn + fn)\n",
    "\n",
    "print(\"Recal: %g\" %(r*100))\n",
    "print(\"Precision: %g\" %(p*100))\n",
    "print(\"Accuracy: %g\" %(a*100))\n",
    "\n",
    "#=============================================================\n",
    "\n",
    "cv_predictions = cvModel.transform(testData)\n",
    "\n",
    "y_actu = cv_predictions.select(\"label\").toPandas()\n",
    "y_pred = cv_predictions.select(\"prediction\").toPandas()\n",
    "\n",
    "cm = confusion_matrix(y_actu, y_pred)\n",
    "\n",
    "plt.clf()\n",
    "plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Wistia)\n",
    "classNames = ['Negative','Positive']\n",
    "plt.title('CROSS-VALIDATION FOR LOGISTIC REGRESSION')\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "tick_marks = np.arange(len(classNames))\n",
    "plt.xticks(tick_marks, classNames, rotation=45)\n",
    "plt.yticks(tick_marks, classNames)\n",
    "\n",
    "#TN, FP, FN, TP = confusion_matrix([0, 1, 0, 1], [1, 1, 1, 0]).ravel()\n",
    "\n",
    "s = [['TN','FP'], ['FN', 'TP']]\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        plt.text(j,i, str(s[i][j])+\" = \"+str(cm[i][j]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# create the trainer and set its parameters\n",
    "nb = NaiveBayes(smoothing=1, modelType=\"multinomial\",)\n",
    "\n",
    "# train the model\n",
    "model = nb.fit(trainingData)\n",
    "\n",
    "# select example rows to display.\n",
    "predictions = model.transform(testData)\n",
    "#predictions.filter(predictions['prediction'] == 0) \\\n",
    "#    .select(\"url\",\"probability\",\"label\",\"prediction\") \\\n",
    "#    .orderBy(\"probability\", ascending=False) \\\n",
    "#    .show(n = 20, truncate = 30)\n",
    "\n",
    "# compute accuracy on the test set\n",
    "evaluator = BinaryClassificationEvaluator(rawPredictionCol=\"prediction\")\n",
    "print(\"Test: Area Under ROC: \" + str(evaluator.evaluate(predictions, {evaluator.metricName: \"areaUnderROC\"})))\n",
    "\n",
    "#===========================\n",
    "df = predictions.select('prediction', 'label')\n",
    "#predictionAndLabels=df.rdd\n",
    "\n",
    "#metrics = MulticlassMetrics(predictionAndLabels) \n",
    "\n",
    "#accuracy=(cm[0][0]+cm[1][1])/cm.sum()\n",
    "#print(accuracy)\n",
    "\n",
    "tp = df[(df.label == 1) & (df.prediction == 1)].count()\n",
    "tn = df[(df.label == 0) & (df.prediction == 0)].count()\n",
    "fp = df[(df.label == 0) & (df.prediction == 1)].count()\n",
    "fn = df[(df.label == 1) & (df.prediction == 0)].count()\n",
    "\n",
    "print(\"True Positives: %g\" % tp)\n",
    "print(\"True Negative: %g\" % tn)\n",
    "print(\"False Positive: %g\" % fp)\n",
    "print(\"False Negative: %g\" % fn)\n",
    "\n",
    "print(\"Total: %g\" % (df.count()))\n",
    "\n",
    "r = float(tp)/(tp + fn)\n",
    "p = float(tp) / (tp + fp)\n",
    "a = float(tp + tn) / (tp + fp + tn + fn)\n",
    "\n",
    "print(\"Recal: %g\" %(r*100))\n",
    "print(\"Precision: %g\" %(p*100))\n",
    "print(\"Accuracy: %g\" %(a*100))\n",
    "\n",
    "#===========================ploting\n",
    "\n",
    "#plt.clf()\n",
    "nb_predictions = model.transform(testData)\n",
    "\n",
    "y_actu = nb_predictions.select(\"label\").toPandas()\n",
    "y_pred = nb_predictions.select(\"prediction\").toPandas()\n",
    "\n",
    "cm = confusion_matrix(y_actu, y_pred)\n",
    "\n",
    "plt.clf()\n",
    "plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Wistia)\n",
    "classNames = ['Negative','Positive']\n",
    "plt.title('Naive Bayes')\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "tick_marks = np.arange(len(classNames))\n",
    "plt.xticks(tick_marks, classNames, rotation=45)\n",
    "plt.yticks(tick_marks, classNames)\n",
    "\n",
    "#TN, FP, FN, TP = confusion_matrix([0, 1, 0, 1], [1, 1, 1, 0]).ravel()\n",
    "\n",
    "s = [['TN','FP'], ['FN', 'TP']]\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        plt.text(j,i, str(s[i][j])+\" = \"+str(cm[i][j]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#==============[ Linear Support Vector Machine ]=====================\n",
    "\n",
    "for i in range(1, 2):\n",
    "    \n",
    "\n",
    "    lsvc = LinearSVC(maxIter=10, regParam=0.3)\n",
    "\n",
    "    # Fit the model\n",
    "    lsvcModel = lsvc.fit(trainingData)\n",
    "\n",
    "    predictions = lsvcModel.transform(testData)\n",
    "\n",
    "    #predictions.select(\"url\", \"label\", \"prediction\").show(n=5, truncate = 100)\n",
    "\n",
    "    # Select (prediction, true label) and compute test error\n",
    "    evaluator = RegressionEvaluator(\n",
    "        labelCol=\"label\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "    rmse = evaluator.evaluate(predictions)\n",
    "    print(\"Root Mean Squared Error (RMSE) on test data = %g\" % rmse)\n",
    "\n",
    "    # Evaluate model\n",
    "    evaluator = BinaryClassificationEvaluator()\n",
    "    accuracy = evaluator.evaluate(predictions)\n",
    "\n",
    "    \n",
    "    #================================================================\n",
    "    df = predictions.select('prediction', 'label')\n",
    "    predictionAndLabels=df.rdd\n",
    "\n",
    "    metrics = MulticlassMetrics(predictionAndLabels) \n",
    "\n",
    "    \n",
    "\n",
    "    tp = df[(df.label == 1) & (df.prediction == 1)].count()\n",
    "    tn = df[(df.label == 0) & (df.prediction == 0)].count()\n",
    "    fp = df[(df.label == 0) & (df.prediction == 1)].count()\n",
    "    fn = df[(df.label == 1) & (df.prediction == 0)].count()\n",
    "\n",
    "    print(\"True Positives: %g\" % tp)\n",
    "    print(\"True Negative: %g\" % tn)\n",
    "    print(\"False Positive: %g\" % fp)\n",
    "    print(\"False Negative: %g\" % fn)\n",
    "\n",
    "    print(\"Total: %g\" % (df.count()))\n",
    "\n",
    "    r = float(tp)/(tp + fn)\n",
    "    p = float(tp) / (tp + fp)\n",
    "    a = float(tp + tn) / (tp + fp + tn + fn)\n",
    "\n",
    "    print(\"Recal: %g\" %(r*100))\n",
    "    print(\"Precision: %g\" %(p*100))\n",
    "    print(\"Accuracy: %g\" %(a*100))\n",
    "\n",
    "#=============================================================\n",
    "    \n",
    "    #==================[ Confusing Matrix Calculation and Plotting ]\n",
    "    lsvm_predictions = lsvcModel.transform(testData)\n",
    "\n",
    "\n",
    "    y_actu = lsvm_predictions.select(\"label\").toPandas()\n",
    "    y_pred = lsvm_predictions.select(\"prediction\").toPandas()\n",
    "\n",
    "    cm = confusion_matrix(y_actu, y_pred)\n",
    "\n",
    "    plt.clf()\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Wistia)\n",
    "    classNames = ['Negative','Positive']\n",
    "    plt.title('LINEAR SUPPORT VECTOR MACHINE')\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    tick_marks = np.arange(len(classNames))\n",
    "    plt.xticks(tick_marks, classNames, rotation=45)\n",
    "    plt.yticks(tick_marks, classNames)\n",
    "\n",
    "    #TN, FP, FN, TP = confusion_matrix([0, 1, 0, 1], [1, 1, 1, 0]).ravel()\n",
    "\n",
    "    s = [['TN','FP'], ['FN', 'TP']]\n",
    "    for i in range(2):\n",
    "        for j in range(2):\n",
    "            plt.text(j,i, str(s[i][j])+\" = \"+str(cm[i][j]))\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One-vs-Rest Classifier ( a.k.a One-vs-All )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#==============[ One-vs-Rest classifier (a.k.a. One-vs-All ]=====================\n",
    "\n",
    "for i in range(1, 2):\n",
    "    \n",
    "    # instantiate the base classifier.\n",
    "    #lr = LogisticRegression(maxIter=10, tol=1E-6, fitIntercept=True)\n",
    "    lr = LogisticRegression(maxIter=10, regParam=0.001, elasticNetParam=0, tol=1E-6, fitIntercept=True )\n",
    "\n",
    "    # instantiate the One Vs Rest Classifier.\n",
    "    ovr = OneVsRest(classifier=lr)\n",
    "\n",
    "    # train the multiclass model.\n",
    "    ovrModel = ovr.fit(trainingData)\n",
    "\n",
    "    # score the model on test data.\n",
    "    predictions = ovrModel.transform(testData)\n",
    "\n",
    "    # obtain evaluator.\n",
    "    evaluator = MulticlassClassificationEvaluator(metricName=\"accuracy\")\n",
    "\n",
    "    # compute the classification error on test data.\n",
    "    accuracy = evaluator.evaluate(predictions)\n",
    "    print(\"Test Error = %g\" % (1.0 - accuracy))\n",
    "    print(\"\\nAccuracy on Test Data = %g\" % (accuracy*100))\n",
    "    \n",
    "    evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "    accuracy = evaluator.evaluate(predictions)\n",
    "    print(\"Accuracy = %g\" % (accuracy*100))\n",
    "\n",
    "    evaluatorf1 = MulticlassClassificationEvaluator( predictionCol=\"prediction\", metricName=\"f1\")\n",
    "    f1 = evaluatorf1.evaluate(predictions)\n",
    "    print(\"f1 = %g\" % (f1*100))\n",
    " \n",
    "     #================================================================\n",
    "    df = predictions.select('prediction', 'label')\n",
    "    predictionAndLabels=df.rdd\n",
    "\n",
    "    metrics = MulticlassMetrics(predictionAndLabels) \n",
    "\n",
    "    #accuracy=(cm[0][0]+cm[1][1])/cm.sum()\n",
    "    #print(accuracy)\n",
    "\n",
    "    tp = df[(df.label == 1) & (df.prediction == 1)].count()\n",
    "    tn = df[(df.label == 0) & (df.prediction == 0)].count()\n",
    "    fp = df[(df.label == 0) & (df.prediction == 1)].count()\n",
    "    fn = df[(df.label == 1) & (df.prediction == 0)].count()\n",
    "\n",
    "    print(\"True Positives: %g\" % tp)\n",
    "    print(\"True Negative: %g\" % tn)\n",
    "    print(\"False Positive: %g\" % fp)\n",
    "    print(\"False Negative: %g\" % fn)\n",
    "\n",
    "    print(\"Total: %g\" % (df.count()))\n",
    "\n",
    "    r = float(tp)/(tp + fn)\n",
    "    p = float(tp) / (tp + fp)\n",
    "    a = float(tp + tn) / (tp + fp + tn + fn)\n",
    "\n",
    "    print(\"Recal: %g\" %(r*100))\n",
    "    print(\"Precision: %g\" %(p*100))\n",
    "    print(\"Accuracy: %g\" %(a*100))\n",
    "\n",
    "#=============================================================\n",
    "    \n",
    "    \n",
    "    ovr_predictions = ovrModel.transform(testData)\n",
    "\n",
    "\n",
    "    y_actu = ovr_predictions.select(\"label\").toPandas()\n",
    "    y_pred = ovr_predictions.select(\"prediction\").toPandas()\n",
    "\n",
    "    cm = confusion_matrix(y_actu, y_pred)\n",
    "\n",
    "    plt.clf()\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Wistia)\n",
    "    classNames = ['Negative','Positive']\n",
    "    plt.title('ONE-VS-RES CLASSIFIER (A.K.A ONE-VS-ALL)')\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    tick_marks = np.arange(len(classNames))\n",
    "    plt.xticks(tick_marks, classNames, rotation=45)\n",
    "    plt.yticks(tick_marks, classNames)\n",
    "\n",
    "    #TN, FP, FN, TP = confusion_matrix([0, 1, 0, 1], [1, 1, 1, 0]).ravel()\n",
    "\n",
    "    s = [['TN','FP'], ['FN', 'TP']]\n",
    "    for i in range(2):\n",
    "        for j in range(2):\n",
    "            plt.text(j,i, str(s[i][j])+\" = \"+str(cm[i][j]))\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
