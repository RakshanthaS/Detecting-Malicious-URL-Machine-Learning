{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import Tokenizer, RegexTokenizer\n",
    "from pyspark.ml.classification import LinearSVC\n",
    "from pyspark.sql.functions import col, udf\n",
    "from pyspark.sql.types import IntegerType\n",
    "from pyspark.ml.feature import NGram,HashingTF, IDF\n",
    "from pyspark.ml.feature import StandardScaler\n",
    "from pyspark.sql.functions import lit\n",
    "from pyspark.mllib.feature import StandardScaler, StandardScalerModel\n",
    "from pyspark.mllib.linalg import Vectors\n",
    "from pyspark.mllib.util import MLUtils\n",
    "from pyspark.ml.classification import LogisticRegression, OneVsRest\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.sql import Row\n",
    "from pyspark.ml.feature import RegexTokenizer, StopWordsRemover, CountVectorizer\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml.feature import Word2Vec\n",
    "\n",
    "from pyspark import SparkContext\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    spark = SparkSession\\\n",
    "        .builder\\\n",
    "        .appName(\"Detecting-Malicious-URL App\")\\\n",
    "        .getOrCreate()\n",
    "\n",
    "#Reading in the URL file and storing into dataframe\n",
    "data_df = spark.read.csv(path='processed_data/dataset_customized.csv',\n",
    "                        sep=',',\n",
    "                        encoding='UTF-8',\n",
    "                        comment=None,\n",
    "                        header=True, \n",
    "                        inferSchema=True)\n",
    "\n",
    "#Uncomment the following two lines if kaggle datasets is used...and replace data_df variable above with raw_data\n",
    "#indexer = StringIndexer(inputCol=\"lable\", outputCol=\"label\")\n",
    "#data_df = indexer.fit(raw_data).transform(raw_data).select(\"url\", \"label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Dataset Count: 957566\n",
      "Test Dataset Count: 240580\n",
      "Total Dataset Count: 1198146\n"
     ]
    }
   ],
   "source": [
    "#Tokennize the TrainData - sparse the URL string into words\n",
    "regexTokenizer = RegexTokenizer(inputCol=\"url\", outputCol=\"Words\", pattern=\"\\\\W\")\n",
    "\n",
    "#determing components to be removed in the URL\n",
    "add_stopWords = [\"http\", \"https\", \"www\", \"ftp\"]\n",
    "\n",
    "#Removing the above stop words  from the tokenized data\n",
    "stopwordsRemover = StopWordsRemover(inputCol=regexTokenizer.getOutputCol(), outputCol=\"Filtered\").setStopWords(add_stopWords)\n",
    "\n",
    "#Convert the words to ngrams. Note: this is not used in production as it gives less results during model training\n",
    "ngram = NGram(n=3, inputCol=stopwordsRemover.getOutputCol(), outputCol=\"Ngrams\")\n",
    "\n",
    "#Word2Vec - Note: this is not used in production as it gives less results during model training\n",
    "word2Vec = Word2Vec(vectorSize=1000, minCount=5, inputCol=stopwordsRemover.getOutputCol(), outputCol=\"features\")\n",
    "\n",
    "#Hashing the data - Note: this is not used in production as it gives less results during model training\n",
    "hashingTF = HashingTF(inputCol=ngram.getOutputCol(), outputCol=\"rawFeatures\")\n",
    "\n",
    "#Note: this is not used in production as it gives less results during model training\n",
    "idf = IDF(inputCol=hashingTF.getOutputCol(), outputCol=\"features\") \n",
    "\n",
    "#CountVectorizer converts the the words into feature vectors - Thi is used as it gives better results\n",
    "countVectors = CountVectorizer(inputCol=stopwordsRemover.getOutputCol(), outputCol=\"features\", vocabSize=10000, minDF=5)\n",
    "\n",
    "#creating the pipepline of steps to be performed in order\n",
    "pipeline = Pipeline(stages=[regexTokenizer,stopwordsRemover, countVectors ])\n",
    "\n",
    "# Fit the pipeline to training documents.\n",
    "pipelineFit = pipeline.fit(data_df)\n",
    "\n",
    "#Transform the pipeline to dataset\n",
    "dataset = pipelineFit.transform(data_df)\n",
    "\n",
    "#randomly split the dataset to traning and testing 80%, 20% respectively\n",
    "(trainingData, testData) = dataset.randomSplit([0.8, 0.2], seed = 100)\n",
    "print(\"Training Dataset Count: \" + str(trainingData.count()))\n",
    "print(\"Test Dataset Count: \" + str(testData.count()))\n",
    "print(\"Total Dataset Count: \" + str(dataset.count()))\n",
    "#dataset.show(truncate = 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Root Mean Squared Error (RMSE) on test data = 0.342964\n",
      "\n",
      "Accuracy on Test Data = 88.6028\n",
      "\n",
      "Root Mean Squared Error (RMSE) on test data = 0.342903\n",
      "\n",
      "Accuracy on Test Data = 88.5872\n",
      "\n",
      "Root Mean Squared Error (RMSE) on test data = 0.342958\n",
      "\n",
      "Accuracy on Test Data = 88.5863\n",
      "\n",
      "Root Mean Squared Error (RMSE) on test data = 0.34297\n",
      "\n",
      "Accuracy on Test Data = 88.601\n",
      "\n",
      "Root Mean Squared Error (RMSE) on test data = 0.34297\n",
      "\n",
      "Accuracy on Test Data = 88.601\n",
      "\n",
      "Root Mean Squared Error (RMSE) on test data = 0.342909\n",
      "\n",
      "Accuracy on Test Data = 88.5856\n",
      "\n",
      "Root Mean Squared Error (RMSE) on test data = 0.342964\n",
      "\n",
      "Accuracy on Test Data = 88.5993\n",
      "\n",
      "Root Mean Squared Error (RMSE) on test data = 0.342933\n",
      "\n",
      "Accuracy on Test Data = 88.6035\n",
      "\n",
      "Root Mean Squared Error (RMSE) on test data = 0.342903\n",
      "\n",
      "Accuracy on Test Data = 88.59\n",
      "\n",
      "Root Mean Squared Error (RMSE) on test data = 0.342952\n",
      "\n",
      "Accuracy on Test Data = 88.6015\n",
      "\n",
      "Root Mean Squared Error (RMSE) on test data = 0.342927\n",
      "\n",
      "Accuracy on Test Data = 88.6027\n",
      "\n",
      "Root Mean Squared Error (RMSE) on test data = 0.342933\n",
      "\n",
      "Accuracy on Test Data = 88.5996\n",
      "\n",
      "Root Mean Squared Error (RMSE) on test data = 0.342952\n",
      "\n",
      "Accuracy on Test Data = 88.5877\n",
      "\n",
      "Root Mean Squared Error (RMSE) on test data = 0.342958\n",
      "\n",
      "Accuracy on Test Data = 88.5863\n",
      "\n",
      "Root Mean Squared Error (RMSE) on test data = 0.342909\n",
      "\n",
      "Accuracy on Test Data = 88.5912\n",
      "\n",
      "Root Mean Squared Error (RMSE) on test data = 0.342909\n",
      "\n",
      "Accuracy on Test Data = 88.601\n",
      "\n",
      "Root Mean Squared Error (RMSE) on test data = 0.342976\n",
      "\n",
      "Accuracy on Test Data = 88.5832\n",
      "\n",
      "Root Mean Squared Error (RMSE) on test data = 0.342964\n",
      "\n",
      "Accuracy on Test Data = 88.5897\n",
      "\n",
      "Root Mean Squared Error (RMSE) on test data = 0.342994\n",
      "\n",
      "Accuracy on Test Data = 88.5895\n",
      "\n",
      "Root Mean Squared Error (RMSE) on test data = 0.342903\n",
      "\n",
      "Accuracy on Test Data = 88.5969\n",
      "\n",
      "Root Mean Squared Error (RMSE) on test data = 0.342927\n",
      "\n",
      "Accuracy on Test Data = 88.5933\n",
      "\n",
      "Root Mean Squared Error (RMSE) on test data = 0.343006\n",
      "\n",
      "Accuracy on Test Data = 88.5952\n",
      "\n",
      "Root Mean Squared Error (RMSE) on test data = 0.342903\n",
      "\n",
      "Accuracy on Test Data = 88.5952\n",
      "\n",
      "Root Mean Squared Error (RMSE) on test data = 0.34297\n",
      "\n",
      "Accuracy on Test Data = 88.5906\n",
      "\n",
      "Root Mean Squared Error (RMSE) on test data = 0.342921\n",
      "\n",
      "Accuracy on Test Data = 88.595\n",
      "\n",
      "Root Mean Squared Error (RMSE) on test data = 0.342939\n",
      "\n",
      "Accuracy on Test Data = 88.5998\n",
      "\n",
      "Root Mean Squared Error (RMSE) on test data = 0.342897\n",
      "\n",
      "Accuracy on Test Data = 88.5994\n",
      "\n",
      "Root Mean Squared Error (RMSE) on test data = 0.342879\n",
      "\n",
      "Accuracy on Test Data = 88.5888\n",
      "\n",
      "Root Mean Squared Error (RMSE) on test data = 0.34297\n",
      "\n",
      "Accuracy on Test Data = 88.5972\n",
      "\n",
      "Root Mean Squared Error (RMSE) on test data = 0.342988\n",
      "\n",
      "Accuracy on Test Data = 88.6045\n",
      "\n",
      "Average Accuracy on test for 30 run is: 88.5948\n"
     ]
    }
   ],
   "source": [
    "#==============[ LOGISTIC REGRESSION ]=========================\n",
    "accuracy = 0.0\n",
    "average_accuracy = 0.0\n",
    "\n",
    "\n",
    "# Build logistic regresssion model\n",
    "for i in range(1,31):\n",
    "    # Fit the pipeline to training documents.\n",
    "    pipelineFit = pipeline.fit(data_df)\n",
    "\n",
    "    #Transform the pipeline to dataset\n",
    "    dataset = pipelineFit.transform(data_df)\n",
    "    \n",
    "    #randomly split the dataset to traning and testing 80%, 20% respectively\n",
    "    (trainingData, testData) = dataset.randomSplit([0.8, 0.2], seed = 100)\n",
    "    \n",
    "    lr = LogisticRegression(maxIter=10000, regParam=0.3, elasticNetParam=0, family = \"binomial\")\n",
    "    # Train model using logisitic regression\n",
    "    lrModel = lr.fit(trainingData)\n",
    "\n",
    "#beta = np.sort(lrModel.coefficients)\n",
    "#plt.plot(beta)\n",
    "#plt.ylabel('Beta Coefficients')\n",
    "#plt.show()\n",
    "\n",
    "# Extract the summary from the returned LogisticRegressionModel instance trained\n",
    "#trainingSummary = lrModel.summary\n",
    "\n",
    "#Obtain the objective per iteration\n",
    "#objectiveHistory = trainingSummary.objectiveHistory\n",
    "#plt.plot(objectiveHistory)\n",
    "#plt.ylabel('Objective Function')\n",
    "#plt.xlabel('Iteration')\n",
    "#plt.show()\n",
    "\n",
    "#pr = trainingSummary.pr.toPandas()\n",
    "#plt.plot(pr['recall'],pr['precision'])\n",
    "#plt.ylabel('Precision')\n",
    "#plt.xlabel('Recall')\n",
    "#plt.show()\n",
    "\n",
    "#Obtain the receiver-operating characteristic as a dataframe and areaUnderROC.\n",
    "#print(\"areaUnderROC: \" + str(trainingSummary.areaUnderROC))\n",
    "\n",
    "#trainingSummary.roc.show(n=10, truncate=15)\n",
    "#roc = trainingSummary.roc.toPandas()\n",
    "#plt.plot(roc['FPR'],roc['TPR'])\n",
    "#plt.ylabel('False Positive Rate')\n",
    "#plt.xlabel('True Positive Rate')\n",
    "#plt.title('ROC Curve')\n",
    "#plt.show()\n",
    "\n",
    "#Set the model threshold to maximize F-Measure\n",
    "#trainingSummary.fMeasureByThreshold.show(n=10, truncate = 15)\n",
    "#f = trainingSummary.fMeasureByThreshold.toPandas()\n",
    "#plt.plot(f['threshold'],f['F-Measure'])\n",
    "#plt.ylabel('F-Measure')\n",
    "#plt.xlabel('Threshold')\n",
    "#plt.show()\n",
    "\n",
    "#Doing the prediction using test data\n",
    "#Label is not used in test data\n",
    "    predictions = lrModel.transform(testData)\n",
    "\n",
    "  #  predictions.select(\"url\", \"label\", \"prediction\").show(n=5, truncate = 100)\n",
    "# Select (prediction, true label) and compute test error\n",
    "    evaluator = RegressionEvaluator(\n",
    "        labelCol=\"label\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "    rmse = evaluator.evaluate(predictions)\n",
    "    print(\"\\nRoot Mean Squared Error (RMSE) on test data = %g\" % rmse)\n",
    "\n",
    "    # Evaluate model\n",
    "    evaluator = BinaryClassificationEvaluator()\n",
    "    accuracy = evaluator.evaluate(predictions)\n",
    "    \n",
    "    average_accuracy = accuracy + average_accuracy\n",
    "\n",
    "    print(\"\\nAccuracy on Test Data = %g\" % (accuracy*100))\n",
    "\n",
    "average_accuracy = average_accuracy/i    \n",
    "print(\"\\nAverage Accuracy on test for %i run is: %g\" % (i, (average_accuracy *100)))\n",
    "#evaluator = BinaryClassificationEvaluator(rawPredictionCol=\"rawPrediction\")\n",
    "#print(\"Test: Area Under ROC: \" + str(evaluator.evaluate(predictions, {evaluator.metricName: \"areaUnderROC\"})))\n",
    "\n",
    "#predictions.filter(predictions['prediction'] == 0) \\\n",
    "#    .select(\"url\", \"label\",\"prediction\") \\\n",
    "#    .orderBy(\"probability\", ascending=False) \\\n",
    "#    .show(n = 10, truncate = 80)\n",
    "#Precision measures the percentage of URLs flagged as malicious that were correctly classified\n",
    "#Recall measures the percentage of actual Malicious URLs that were correctly classified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: Area Under ROC: 0.9763079945884876\n"
     ]
    }
   ],
   "source": [
    "#==============[ Cross Validation for Logistic Regression ]=====================\n",
    "# Creating ParamGrid for Cross Validation\n",
    "paramGrid = (ParamGridBuilder()\n",
    "             .addGrid(lr.regParam, [0.1, 0.3, 0.5]) # regularization parameter\n",
    "             .addGrid(lr.elasticNetParam, [0.0, 0.1, 0.2]) # Elastic Net Parameter (Ridge = 0)\n",
    "#            .addGrid(model.maxIter, [10, 20, 50]) #Number of iterations\n",
    "#            .addGrid(idf.numFeatures, [10, 100, 1000]) # Number of features\n",
    "             .build())\n",
    "\n",
    "# Create 10-fold CrossValidator\n",
    "cv = CrossValidator(estimator=lr, \\\n",
    "                    estimatorParamMaps=paramGrid, \\\n",
    "                    evaluator=evaluator, \\\n",
    "                    numFolds=10)\n",
    "\n",
    "# Run cross validations\n",
    "cvModel = cv.fit(trainingData)\n",
    "# this will likely take a fair amount of time because of the amount of models that we're creating and testing\n",
    "\n",
    "# Use test set here so we can measure the accuracy of our model on new data\n",
    "predictions = cvModel.transform(testData)\n",
    "\n",
    "# cvModel uses the best model found from the Cross Validation\n",
    "# Evaluate best model\n",
    "print(\"Test: Area Under ROC: \" + str(evaluator.evaluate(predictions, {evaluator.metricName: \"areaUnderROC\"})))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error (RMSE) on test data = 0.266667\n",
      "\n",
      "Accuracy on Test Data = 86.9483\n",
      "Root Mean Squared Error (RMSE) on test data = 0.266714\n",
      "\n",
      "Accuracy on Test Data = 86.4946\n"
     ]
    }
   ],
   "source": [
    "#==============[ Linear Support Vector Machine ]=====================\n",
    "\n",
    "for i in range(1, 3):\n",
    "    \n",
    "     # Fit the pipeline to training documents.\n",
    "    pipelineFit = pipeline.fit(data_df)\n",
    "\n",
    "    #Transform the pipeline to dataset\n",
    "    dataset = pipelineFit.transform(data_df)\n",
    "    \n",
    "    #randomly split the dataset to traning and testing 80%, 20% respectively\n",
    "    (trainingData, testData) = dataset.randomSplit([0.8, 0.2], seed = 100)\n",
    "\n",
    "    lsvc = LinearSVC(maxIter=10, regParam=0.3)\n",
    "\n",
    "    # Fit the model\n",
    "    lsvcModel = lsvc.fit(trainingData)\n",
    "\n",
    "    predictions = lsvcModel.transform(testData)\n",
    "\n",
    "    #predictions.select(\"url\", \"label\", \"prediction\").show(n=5, truncate = 100)\n",
    "\n",
    "    # Select (prediction, true label) and compute test error\n",
    "    evaluator = RegressionEvaluator(\n",
    "        labelCol=\"label\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "    rmse = evaluator.evaluate(predictions)\n",
    "    print(\"Root Mean Squared Error (RMSE) on test data = %g\" % rmse)\n",
    "\n",
    "    # Evaluate model\n",
    "    evaluator = BinaryClassificationEvaluator()\n",
    "    accuracy = evaluator.evaluate(predictions)\n",
    "\n",
    "    print(\"\\nAccuracy on Test Data = %g\" % (accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error = 0.0689667\n",
      "\n",
      "Accuracy on Test Data = 93.1033\n",
      "Test Error = 0.0689293\n",
      "\n",
      "Accuracy on Test Data = 93.1071\n",
      "Test Error = 0.0689043\n",
      "\n",
      "Accuracy on Test Data = 93.1096\n"
     ]
    }
   ],
   "source": [
    "#==============[ One-vs-Rest classifier (a.k.a. One-vs-All ]=====================\n",
    "\n",
    "for i in range(1, 4):\n",
    "    \n",
    "     # Fit the pipeline to training documents.\n",
    "    pipelineFit = pipeline.fit(data_df)\n",
    "\n",
    "    #Transform the pipeline to dataset\n",
    "    dataset = pipelineFit.transform(data_df)\n",
    "    \n",
    "    #randomly split the dataset to traning and testing 80%, 20% respectively\n",
    "    (trainingData, testData) = dataset.randomSplit([0.8, 0.2], seed = 100)\n",
    "\n",
    "    # instantiate the base classifier.\n",
    "    lr = LogisticRegression(maxIter=10, tol=1E-6, fitIntercept=True)\n",
    "\n",
    "    # instantiate the One Vs Rest Classifier.\n",
    "    ovr = OneVsRest(classifier=lr)\n",
    "\n",
    "    # train the multiclass model.\n",
    "    ovrModel = ovr.fit(trainingData)\n",
    "\n",
    "    # score the model on test data.\n",
    "    predictions = ovrModel.transform(testData)\n",
    "\n",
    "    # obtain evaluator.\n",
    "    evaluator = MulticlassClassificationEvaluator(metricName=\"accuracy\")\n",
    "\n",
    "    evaluator1 = BinaryClassificationEvaluator()\n",
    " \n",
    "  #  predictions.select(\"url\", \"label\", \"prediction\").show(n=5, truncate = 100)\n",
    "\n",
    "\n",
    "    # compute the classification error on test data.\n",
    "    accuracy = evaluator.evaluate(predictions)\n",
    "    print(\"Test Error = %g\" % (1.0 - accuracy))\n",
    "    print(\"\\nAccuracy on Test Data = %g\" % (accuracy*100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----+\n",
      "|         url|label|\n",
      "+------------+-----+\n",
      "|  0b55.top;1|    1|\n",
      "|  0dfd9x.net|    1|\n",
      "|135cross.com|    1|\n",
      "|     1ct.top|    1|\n",
      "|     1gc.top|    1|\n",
      "|     1gd.top|    1|\n",
      "|   1nr.top;1|    1|\n",
      "|     1nz.top|    1|\n",
      "|     1pn.top|    1|\n",
      "|     1pr.top|    1|\n",
      "|   1qx.top;1|    1|\n",
      "|   1rh.top;1|    1|\n",
      "|     1ri.top|    1|\n",
      "|     1rj.top|    1|\n",
      "|     1rk.top|    1|\n",
      "|     1rx.top|    1|\n",
      "|     1ry.top|    1|\n",
      "|     1rz.top|    1|\n",
      "|     1sb.top|    1|\n",
      "|     1sc.top|    1|\n",
      "+------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>url</th>\n",
       "      <td>0b55.top;1</td>\n",
       "      <td>0dfd9x.net</td>\n",
       "      <td>135cross.com</td>\n",
       "      <td>1ct.top</td>\n",
       "      <td>1gc.top</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                0           1             2        3        4\n",
       "url    0b55.top;1  0dfd9x.net  135cross.com  1ct.top  1gc.top\n",
       "label           1           1             1        1        1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data_df.show()\n",
    "pd.DataFrame(data_df.take(5), columns=data_df.columns).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>198146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label    count\n",
       "0      1   198146\n",
       "1      0  1000000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.groupby('label').count().toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading in the URL file and storing into dataframe\n",
    "data_df = spark.read.csv(path='processed_data/kaggle_dataset.csv',\n",
    "                        sep=',',\n",
    "                        encoding='UTF-8',\n",
    "                        comment=None,\n",
    "                        header=True, \n",
    "                        inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lable</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bad</td>\n",
       "      <td>75643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>good</td>\n",
       "      <td>344821</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  lable   count\n",
       "0   bad   75643\n",
       "1  good  344821"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.groupBy(\"lable\").count().toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
